{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travaux pratiques sur les réseaux d'eau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Données et fonctions du problème"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On charge dans l'environnement :\n",
    "1. les fonctions de Python qui seront utilisées,\n",
    "2. les données du problème,\n",
    "3. les fonctions utilitaires du problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Probleme_R import *\n",
    "from Structures_N import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visualg import Visualg\n",
    "from Verification import Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  On charge les prototypes d'algorithmes d'optimisation :\n",
    "\n",
    "* **Gradient_F** : algorithme de gradient à pas fixe,\n",
    "* **Newton_F** : algorithme de Newton à pas fixe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_F(Oracle, x0, alpha0):\n",
    "    \n",
    "    from numpy.linalg import norm\n",
    "    from time import process_time\n",
    "    \n",
    "    ##### Initialisation des variables\n",
    "    \n",
    "    iter_max = 10000\n",
    "    gradient_step = alpha0\n",
    "    threshold = 0.000001\n",
    "    \n",
    "    gradient_norm_list = []\n",
    "    gradient_step_list = []\n",
    "    critere_list = []\n",
    "\n",
    "    time_start = process_time()\n",
    "    \n",
    "    x = x0\n",
    "\n",
    "    ##### Boucle sur les iterations\n",
    "\n",
    "    for k in range(iter_max):\n",
    "        \n",
    "        # Valeur du critere et du gradient\n",
    "        critere, gradient = Oracle(x)\n",
    "\n",
    "        # Test de convergence\n",
    "        gradient_norm = norm(gradient)\n",
    "        if gradient_norm <= threshold:\n",
    "            break\n",
    "\n",
    "        # Direction de descente\n",
    "        direction = -gradient\n",
    "        \n",
    "        # Mise a jour des variables\n",
    "        x = x + (gradient_step*direction)\n",
    "        \n",
    "        # Evolution du gradient, du pas, et du critere\n",
    "        gradient_norm_list.append(gradient_norm)\n",
    "        gradient_step_list.append(gradient_step)\n",
    "        critere_list.append(critere)\n",
    "    \n",
    "    ##### Resultats de l'optimisation\n",
    "\n",
    "    critere_opt = critere\n",
    "    gradient_opt = gradient\n",
    "    x_opt = x\n",
    "    time_cpu = process_time() - time_start\n",
    "    \n",
    "    print()\n",
    "    print('Iteration :', k)\n",
    "    print('Temps CPU :', time_cpu)\n",
    "    print('Critere optimal :', critere_opt)\n",
    "    print('Norme du gradient :', norm(gradient_opt))\n",
    "    \n",
    "    # Visualisation de la convergence\n",
    "    Visualg(gradient_norm_list, gradient_step_list, critere_list)\n",
    "    \n",
    "    return critere_opt, gradient_opt, x_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Newton_F(Oracle, x0, alpha0):\n",
    "    \n",
    "    from numpy.linalg import norm\n",
    "    from numpy.linalg import solve\n",
    "    from time import process_time\n",
    "    \n",
    "    ##### Initialisation des variables    \n",
    "    \n",
    "    iter_max = 100\n",
    "    gradient_step = alpha0\n",
    "    threshold = 0.000001\n",
    "    \n",
    "    gradient_norm_list = []\n",
    "    gradient_step_list = []\n",
    "    critere_list = []\n",
    "\n",
    "    time_start = process_time()\n",
    "    \n",
    "    x = x0\n",
    "\n",
    "    ##### Boucle sur les iterations\n",
    "    \n",
    "    for k in range(iter_max):\n",
    "        \n",
    "        # Valeur du critere et du gradient\n",
    "        critere, gradient, hessien = Oracle(x)\n",
    "\n",
    "        # Test de convergence\n",
    "        gradient_norm = norm(gradient)\n",
    "        if gradient_norm <= threshold:\n",
    "            break\n",
    "        \n",
    "        # Direction de descente\n",
    "        direction = - solve(hessien, gradient)\n",
    "        \n",
    "        # Mise a jour des variables\n",
    "        x = x + (gradient_step*direction)\n",
    "        \n",
    "        # Evolution du gradient, du pas, et du critere\n",
    "        gradient_norm_list.append(gradient_norm)\n",
    "        gradient_step_list.append(gradient_step)\n",
    "        critere_list.append(critere)\n",
    "   \n",
    "    ##### Resultats de l'optimisation\n",
    "    \n",
    "    critere_opt = critere\n",
    "    gradient_opt = gradient\n",
    "    x_opt = x\n",
    "    time_cpu = process_time() - time_start\n",
    "\n",
    "    print()\n",
    "    print('Iteration :', k)\n",
    "    print('Temps CPU :', time_cpu)\n",
    "    print('Critere optimal :', critere_opt)\n",
    "    print('Norme du gradient :', norm(gradient_opt))\n",
    "    \n",
    "    # Visualisation de la convergence\n",
    "    Visualg(gradient_norm_list, gradient_step_list, critere_list)\n",
    "    \n",
    "    return critere_opt, gradient_opt, x_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Résolution du problème primal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HydrauliqueP import HydrauliqueP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.a On écrit les oracles pour le problème primal d'optimisation :\n",
    "\n",
    "* **OraclePG** : calcul de la fonction et du gradient,\n",
    "* **OraclePH** : calcul de la fonction du gradient et du Hessien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OraclePG(qc):\n",
    "    \n",
    "    # ---> A COMPLETER\n",
    "    critere = (1/3)*np.dot(q0 + np.dot(B , qc), np.multiply(r,(q0 + np.dot(B , qc)), np.absolute(q0 +  np.dot(B , qc))))\n",
    "    # ---> A COMPLETER\n",
    "    gradient = B.transpose()*(np.multiply(r,q0 +  np.dot(B , qc), np.absolute(q0 +  np.dot(B , qc)))) + np.dot(np.dot(B.transpose(),Ar.transpose()),pr)\n",
    "    \n",
    "    return critere, gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([1,2,3])\n",
    "B = np.array([2,4,6])\n",
    "C = np.array([-1,2,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A,np.multiply(A, B, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OraclePH(qc):\n",
    "    \n",
    "    # ---> A COMPLETER\n",
    "    critere = (1/3)*np.dot(q0 + B * qc, np.multiply(r,(q0 + B * qc), np.absolute(q0 + B * qc)))\n",
    "    # ---> A COMPLETER\n",
    "    gradient = B.transpose()*(np.multiply(r,q0 + B * qc, np.absolute(q0 + B * qc))) + B.transpose()*Ar.transpose()*pr\n",
    "    \n",
    "    return critere, gradient, hessien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On teste la validité des oracles en résolvant le problème :\n",
    "\n",
    "* **OraclePG** avec la méthode du gradient à pas fixe,\n",
    "* **OraclePH** avec la méthode de Newton à pas fixe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MINIMISATION DU PROBLEME PRIMAL\n",
      "\n",
      "ALGORITHME DU GRADIENT A PAS FIXE\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (3,) and (9,) not aligned: 3 (dim 0) != 9 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e58392870e7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ALGORITHME DU GRADIENT A PAS FIXE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradient_F\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOraclePG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mqopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHydrauliqueP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mVerification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-a7ad5680b22e>\u001b[0m in \u001b[0;36mGradient_F\u001b[1;34m(Oracle, x0, alpha0)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# Valeur du critere et du gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mcritere\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOracle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# Test de convergence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-b922aac560e2>\u001b[0m in \u001b[0;36mOraclePG\u001b[1;34m(qc)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# ---> A COMPLETER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mcritere\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mqc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mqc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq0\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mqc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# ---> A COMPLETER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mq0\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mqc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq0\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mqc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (3,) and (9,) not aligned: 3 (dim 0) != 9 (dim 0)"
     ]
    }
   ],
   "source": [
    "x0 = 0.1 * random.normal(size=n-md)\n",
    "print()\n",
    "print(\"MINIMISATION DU PROBLEME PRIMAL\")\n",
    "print()\n",
    "print(\"ALGORITHME DU GRADIENT A PAS FIXE\")\n",
    "copt, gopt, xopt = Gradient_F(OraclePG, x0, 0.0005)\n",
    "qopt, zopt, fopt, popt = HydrauliqueP(xopt, m, mr, md, r, pr, fd, Ar, AdI, B, q0)\n",
    "Verification(A, qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 0.1 * random.normal(size=n-md)\n",
    "print()\n",
    "print(\"MINIMISATION DU PROBLEME PRIMAL\")\n",
    "print()\n",
    "print(\"ALGORITHME DE NEWTON A PAS FIXE\")\n",
    "copt, gopt, xopt = Newton_F(OraclePH, x0, 1)\n",
    "qopt, zopt, fopt, popt = HydrauliqueP(xopt, m, mr, md, r, pr, fd, Ar, AdI, B, q0)\n",
    "Verification(A, qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.b On écrit l'algorithme de recherche linéaire (conditions de Wolfe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wolfe(alpha, x, D, Oracle):\n",
    "    \n",
    "    from numpy import dot\n",
    "    from numpy import inf\n",
    "    from numpy.linalg import norm\n",
    "\n",
    "    ##### Coefficients de la recherche lineaire\n",
    "    \n",
    "    omega_1 = 0.1\n",
    "    omega_2 = 0.9\n",
    "    \n",
    "    alpha_min = 0\n",
    "    alpha_max = inf\n",
    "    \n",
    "    ok = 0\n",
    "    dltx = 0.00000001\n",
    "\n",
    "    ##### Algorithme de Fletcher-Lemarechal\n",
    "    \n",
    "    # Appel de l'oracle au point initial\n",
    "    argout = Oracle(x)\n",
    "    critere = argout[0]\n",
    "    gradient = argout[1]\n",
    "    \n",
    "    # Initialisation de l'algorithme\n",
    "    alpha_n = alpha\n",
    "    xn = x\n",
    "    \n",
    "    # Boucle de calcul du pas\n",
    "    # xn represente le point pour la valeur courante du pas,\n",
    "    # xp represente le point pour la valeur precedente du pas.\n",
    "    while ok == 0:\n",
    "        \n",
    "        # Point precedent pour tester l'indistinguabilite\n",
    "        xp = xn\n",
    "        \n",
    "        # Point actuel\n",
    "        xn = x + alpha_n*D\n",
    "        \n",
    "        # Calcul des conditions de Wolfe\n",
    "        #\n",
    "        # ---> A COMPLETER\n",
    "        # ---> A COMPLETER\n",
    "        \n",
    "        # Test des conditions de Wolfe\n",
    "        #\n",
    "        # - Si les deux conditions de Wolfe sont verifiees,\n",
    "        #   poser ok = 1 : on sort alors de la boucle while\n",
    "        # - Sinon, modifier la valeur de alphan et reboucler\n",
    "        #\n",
    "        # ---> A COMPLETER\n",
    "        # ---> A COMPLETER\n",
    "        \n",
    "        # Test d'indistinguabilite\n",
    "        if norm(xn - xp) < dltx:\n",
    "            ok = 2\n",
    "\n",
    "    return alpha_n, ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.c On écrit l'algorithme du gradient à pas variable et on le teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_V(Oracle, x0, alpha0):\n",
    "    \n",
    "    from numpy.linalg import norm\n",
    "    from time import process_time\n",
    "    \n",
    "    ##### Initialisation des variables\n",
    "\n",
    "    iter_max = 1000\n",
    "    default_gradient_step = alpha0\n",
    "    threshold = 0.000001\n",
    "    \n",
    "    gradient_norm_list = []\n",
    "    gradient_step_list = []\n",
    "    critere_list = []\n",
    "    \n",
    "    time_start = process_time()\n",
    "\n",
    "    x = x0\n",
    "\n",
    "    ##### Boucle sur les iterations\n",
    "\n",
    "    for k in range(iter_max):\n",
    "        \n",
    "        # ---> A COMPLETER\n",
    "        # ---> A COMPLETER\n",
    "    \n",
    "    ##### Resultats de l'optimisation\n",
    "    critere_opt = critere\n",
    "    gradient_opt = gradient\n",
    "    x_opt = x\n",
    "    time_cpu = process_time() - time_start\n",
    "\n",
    "    print()\n",
    "    print('Iteration :', k)\n",
    "    print('Temps CPU :', time_cpu)\n",
    "    print('Critere optimal :', critere_opt)\n",
    "    print('Norme du gradient :', norm(gradient_opt))\n",
    "    \n",
    "    # Visualisation de la convergence\n",
    "    Visualg(gradient_norm_list, gradient_step_list, critere_list)\n",
    "    \n",
    "    return critere_opt, gradient_opt, x_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x0 = 0.1 * random.normal(size=n-md)\n",
    "print()\n",
    "print(\"MINIMISATION DU PROBLEME PRIMAL\")\n",
    "print()\n",
    "print(\"ALGORITHME DU GRADIENT A PAS VARIABLE\")\n",
    "copt, gopt, xopt = Gradient_V(OraclePG, x0, 1)\n",
    "qopt, zopt, fopt, popt = HydrauliqueP(xopt, m, mr, md, r, pr, fd, Ar, AdI, B, q0)\n",
    "Verification(A, qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.d On écrit l'algorithme de gradient conjugué (Polak-Ribière) et on le teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolakRibiere(Oracle, x0, alpha0):\n",
    "    \n",
    "    from numpy import dot\n",
    "    from numpy.linalg import norm\n",
    "    from time import process_time\n",
    "    \n",
    "    ##### Initialisation des variables\n",
    "\n",
    "    iter_max = 1000\n",
    "    default_gradient_step = alpha0\n",
    "    threshold = 0.000001\n",
    "    \n",
    "    gradient_norm_list = []\n",
    "    gradient_step_list = []\n",
    "    critere_list = []\n",
    "    \n",
    "    time_start = process_time()\n",
    "\n",
    "    x = x0\n",
    "    \n",
    "    ##### Boucle sur les iterations\n",
    "    \n",
    "    for k in range(iter_max):\n",
    "        \n",
    "        # ---> A COMPLETER\n",
    "        # ---> A COMPLETER\n",
    "        #\n",
    "        # Attention a l'initialisation de l'algorithme !\n",
    "    \n",
    "    # Resultat de l'optimisation\n",
    "    critere_opt = critere\n",
    "    gradient_opt = gradient\n",
    "    x_opt = x\n",
    "    time_cpu = process_time() - time_start\n",
    "\n",
    "    print()\n",
    "    print('Iteration :', k)\n",
    "    print('Temps CPU :', time_cpu)\n",
    "    print('Critere optimal :', critere_opt)\n",
    "    print('Norme du gradient :', norm(gradient_opt))\n",
    "        \n",
    "    # Visualisation de la convergence\n",
    "    Visualg(gradient_norm_list, gradient_step_list, critere_list)\n",
    "    \n",
    "    return critere_opt, gradient_opt, x_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 0.1 * random.normal(size=n-md)\n",
    "print()\n",
    "print(\"MINIMISATION DU PROBLEME PRIMAL\")\n",
    "print()\n",
    "print(\"ALGORITHME DU GRADIENT CONJUGUE\")\n",
    "copt, gopt, xopt = PolakRibiere(OraclePG, x0, 1)\n",
    "qopt, zopt, fopt, popt = HydrauliqueP(xopt, m, mr, md, r, pr, fd, Ar, AdI, B, q0)\n",
    "Verification(A, qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.e On écrit l'algorithme de quasi-Newton (BFGS) et on le teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFGS(Oracle, x0, alpha0):\n",
    "    \n",
    "    from numpy import dot\n",
    "    from numpy import eye\n",
    "    from numpy import outer\n",
    "    from numpy import vdot\n",
    "    from numpy.linalg import norm\n",
    "    from time import process_time\n",
    "    \n",
    "    ##### Initialisation des variables\n",
    "\n",
    "    iter_max = 250\n",
    "    default_gradient_step = alpha0\n",
    "    threshold = 0.000001\n",
    "    \n",
    "    gradient_norm_list = []\n",
    "    gradient_step_list = []\n",
    "    critere_list = []\n",
    "    \n",
    "    time_start = process_time()\n",
    "\n",
    "    x = x0\n",
    "\n",
    "    ##### Boucle sur les iterations\n",
    "    \n",
    "    for k in range(iter_max):\n",
    "        \n",
    "        # ---> A COMPLETER\n",
    "        # ---> A COMPLETER\n",
    "        #\n",
    "        # Attention a l'initialisation de l'algorithme !\n",
    "    \n",
    "    # Resultat de l'optimisation\n",
    "    critere_opt = critere\n",
    "    gradient_opt = gradient\n",
    "    x_opt = x\n",
    "    time_cpu = process_time() - time_start\n",
    "\n",
    "    print()\n",
    "    print('Iteration :', k)\n",
    "    print('Temps CPU :', time_cpu)\n",
    "    print('Critere optimal :', critere_opt)\n",
    "    print('Norme du gradient :', norm(gradient_opt))\n",
    "        \n",
    "    # Visualisation de la convergence\n",
    "    Visualg(gradient_norm_list, gradient_step_list, critere_list)\n",
    "    \n",
    "    return critere_opt, gradient_opt, x_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 0.1 * random.normal(size=n-md)\n",
    "print()\n",
    "print(\"MINIMISATION DU PROBLEME PRIMAL\")\n",
    "print()\n",
    "print(\"ALGORITHME DE QUASI-NEWTON\")\n",
    "copt, gopt, xopt = BFGS(OraclePG, x0, 1)\n",
    "qopt, zopt, fopt, popt = HydrauliqueP(xopt, m, mr, md, r, pr, fd, Ar, AdI, B, q0)\n",
    "Verification(A, qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.f On écrit l'algorithme de Newton à pas variable et on le teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Newton_V(Oracle, x0, alpha0):\n",
    "    \n",
    "    from numpy.linalg import norm\n",
    "    from numpy.linalg import solve\n",
    "    from time import process_time\n",
    "    \n",
    "    ##### Initialisation des variables  \n",
    "    \n",
    "    iter_max = 100\n",
    "    default_gradient_step = alpha0\n",
    "    threshold = 0.000001\n",
    "    \n",
    "    gradient_norm_list = []\n",
    "    gradient_step_list = []\n",
    "    critere_list = []\n",
    "\n",
    "    time_start = process_time()\n",
    "    \n",
    "    x = x0\n",
    "\n",
    "    ##### Boucle sur les iterations\n",
    "    \n",
    "    for k in range(iter_max):\n",
    "        \n",
    "        # ---> A COMPLETER\n",
    "        # ---> A COMPLETER\n",
    "           \n",
    "    ##### Resultats de l'optimisation\n",
    "    \n",
    "    critere_opt = critere\n",
    "    gradient_opt = gradient\n",
    "    x_opt = x\n",
    "    time_cpu = process_time() - time_start\n",
    "\n",
    "    print()\n",
    "    print('Iteration :', k)\n",
    "    print('Temps CPU :', time_cpu)\n",
    "    print('Critere optimal :', critere_opt)\n",
    "    print('Norme du gradient :', norm(gradient_opt))\n",
    "    \n",
    "    # Visualisation de la convergence\n",
    "    Visualg(gradient_norm_list, gradient_step_list, critere_list)\n",
    "    \n",
    "    return critere_opt, gradient_opt, x_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 0.1 * random.normal(size=n-md)\n",
    "print()\n",
    "print(\"MINIMISATION DU PROBLEME PRIMAL\")\n",
    "print()\n",
    "print(\"ALGORITHME DE NEWTON A PAS VARIABLE\")\n",
    "copt, gopt, xopt = Newton_V(OraclePH, x0, 1)\n",
    "qopt, zopt, fopt, popt = HydrauliqueP(xopt, m, mr, md, r, pr, fd, Ar, AdI, B, q0)\n",
    "Verification(A, qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Résolution du problème dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HydrauliqueD import HydrauliqueD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.a On écrit les oracles pour le problème dual d'optimisation :\n",
    "\n",
    "* **OracleDG** : calcul de la fonction et du gradient,\n",
    "* **OracleDH** : calcul de la fonction du gradient et du Hessien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OracleDG(pd):\n",
    "    \n",
    "    # ---> A COMPLETER\n",
    "    # ---> A COMPLETER\n",
    "    \n",
    "    return critere, gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OracleDH(pd):\n",
    "    \n",
    "    # ---> A COMPLETER\n",
    "    # ---> A COMPLETER\n",
    "    \n",
    "    return critere, gradient, hessien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.b On exécute tous les algorithmes d'optimisation déjà écrits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 100 + random.normal(size=md)\n",
    "print()\n",
    "print(\"MINIMISATION DU PROBLEME DUAL\")\n",
    "print()\n",
    "print(\"ALGORITHME DU GRADIENT A PAS VARIABLE\")\n",
    "copt, gopt, xopt = Gradient_V(OracleDG, x0, 5)\n",
    "qopt, zopt, fopt, popt = HydrauliqueD(xopt, m, mr, r, pr, fd, A, Ar)\n",
    "Verification(A, qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 100 + random.normal(size=md)\n",
    "print()\n",
    "print(\"MINIMISATION DU PROBLEME DUAL\")\n",
    "print()\n",
    "print(\"ALGORITHME DU GRADIENT CONJUGUE\")\n",
    "copt, gopt, xopt = PolakRibiere(OracleDG, x0, 5)\n",
    "qopt, zopt, fopt, popt = HydrauliqueD(xopt, m, mr, r, pr, fd, A, Ar)\n",
    "Verification(A, qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 100 + random.normal(size=md)\n",
    "print()\n",
    "print(\"MINIMISATION DU PROBLEME DUAL\")\n",
    "print()\n",
    "print(\"ALGORITHME DE QUASI-NEWTON\")\n",
    "copt, gopt, xopt = BFGS(OracleDG, x0, 1)\n",
    "qopt, zopt, fopt, popt = HydrauliqueD(xopt, m, mr, r, pr, fd, A, Ar)\n",
    "Verification(A, qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 100 + random.normal(size=md)\n",
    "print()\n",
    "print(\"MINIMISATION DU PROBLEME DUAL\")\n",
    "print()\n",
    "print(\"ALGORITHME DE NEWTON A PAS VARIABLE\")\n",
    "copt, gopt, xopt = Newton_V(OracleDH, x0, 1)\n",
    "qopt, zopt, fopt, popt = HydrauliqueD(xopt, m, mr, r, pr, fd, A, Ar)\n",
    "Verification(A, qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Résolution de grands réseaux (facultatif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On charge dans l'environnement les données du problème\n",
    "\n",
    "Ces données correspondent à un réseau de taille paramétrable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Probleme_P import *\n",
    "from Structures_S import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.a On écrit des oracles primal et dual avec Hessien creux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OraclePHS(qc):\n",
    "    \n",
    "    # ---> A COMPLETER\n",
    "    # ---> A COMPLETER\n",
    "    \n",
    "    return critere, gradient, hessien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OracleDHS(pd):\n",
    "    \n",
    "    # ---> A COMPLETER\n",
    "    # ---> A COMPLETER\n",
    "    \n",
    "    return critere, gradient, hessien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.b On écrit un algorithme de Newton exploitant le creux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Newton_S(Oracle, x0, alpha0):\n",
    "    \n",
    "    from numpy.linalg import norm\n",
    "    from scipy.sparse.linalg import spsolve\n",
    "    from time import process_time\n",
    "    \n",
    "    ##### Initialisation des variables  \n",
    "    \n",
    "    iter_max = 100\n",
    "    default_gradient_step = alpha0\n",
    "    threshold = 0.000001\n",
    "    \n",
    "    gradient_norm_list = []\n",
    "    gradient_step_list = []\n",
    "    critere_list = []\n",
    "\n",
    "    time_start = process_time()\n",
    "    \n",
    "    x = x0\n",
    "\n",
    "    ##### Boucle sur les iterations\n",
    "    \n",
    "    for k in range(iter_max):\n",
    "        \n",
    "        # ---> A COMPLETER\n",
    "        # ---> A COMPLETER\n",
    "           \n",
    "    ##### Resultats de l'optimisation\n",
    "    \n",
    "    critere_opt = critere\n",
    "    gradient_opt = gradient\n",
    "    x_opt = x\n",
    "    time_cpu = process_time() - time_start\n",
    "\n",
    "    print()\n",
    "    print('Iteration :', k)\n",
    "    print('Temps CPU :', time_cpu)\n",
    "    print('Critere optimal :', critere_opt)\n",
    "    print('Norme du gradient :', norm(gradient_opt))\n",
    "    \n",
    "    # Visualisation de la convergence\n",
    "    Visualg(gradient_norm_list, gradient_step_list, critere_list)\n",
    "    \n",
    "    return critere_opt, gradient_opt, x_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.c On résoud le problème dans le primal et dans le dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 0.1 * random.normal(size=n-md)\n",
    "print()\n",
    "print(\"MINIMISATION DU PROBLEME PRIMAL DE GRANDE TAILLE\")\n",
    "print()\n",
    "print(\"ALGORITHME DE NEWTON A PAS VARIABLE\")\n",
    "copt, gopt, xopt = Newton_S(OraclePHS, x0, 1)\n",
    "qopt, zopt, fopt, popt = HydrauliqueP(xopt, m, mr, md, r, pr, fd, Ar, AdI, B, q0)\n",
    "Verification(A, qopt, zopt, fopt, popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 100 + random.normal(size=md)\n",
    "print()\n",
    "print(\"MINIMISATION DU PROBLEME DUAL DE GRANDE TAILLE\")\n",
    "print()\n",
    "print(\"ALGORITHME DE NEWTON A PAS VARIABLE\")\n",
    "copt, gopt, xopt = Newton_S(OracleDHS, x0, 1)\n",
    "qopt, zopt, fopt, popt = HydrauliqueD(xopt, m, mr, r, pr, fd, A, Ar)\n",
    "Verification(A, qopt, zopt, fopt, popt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
